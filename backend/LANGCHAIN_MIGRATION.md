# ğŸ¦œğŸ”— LangChain ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

ê¸°ì¡´ boto3 ì§ì ‘ êµ¬í˜„ ë°©ì‹ì—ì„œ **LangChain**ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•œ ë‚´ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ì™œ LangChainì¸ê°€?](#ì™œ-langchainì¸ê°€)
2. [ë³€ê²½ ì‚¬í•­ ìš”ì•½](#ë³€ê²½-ì‚¬í•­-ìš”ì•½)
3. [ìƒˆë¡œìš´ íŒŒì¼ êµ¬ì¡°](#ìƒˆë¡œìš´-íŒŒì¼-êµ¬ì¡°)
4. [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
5. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
6. [ê¸°ëŠ¥ ë¹„êµ](#ê¸°ëŠ¥-ë¹„êµ)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ğŸ¤” ì™œ LangChainì¸ê°€?

### í”„ë¡œì íŠ¸ íŠ¹ì„± ë¶„ì„

ì´ í”„ë¡œì íŠ¸ëŠ” **ì „í˜•ì ì¸ RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤:

```
1. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (í•˜ì´ë¸Œë¦¬ë“œ: ë²¡í„° + í‚¤ì›Œë“œ)
3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
4. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
5. ì‘ë‹µ ë°˜í™˜
```

**â†’ LangChainì´ íŠ¹í™”ëœ ë¶„ì•¼!**

### LangChainì˜ ì¥ì 

| ì´ìœ  | ì„¤ëª… |
|------|------|
| âœ… **RAG ì „ìš©** | ConversationalRetrievalChain ë“± RAG ì „ìš© ì»´í¬ë„ŒíŠ¸ ì œê³µ |
| âœ… **ì„±ìˆ™ë„** | 200K+ GitHub Stars, ìˆ˜ì²œ ê°œ í”„ë¡œë•ì…˜ ì‚¬ë¡€ |
| âœ… **ìƒì‚°ì„±** | ì½”ë“œ 70% ê°ì†Œ (500ì¤„ â†’ 150ì¤„) |
| âœ… **ëŒ€í™” ê´€ë¦¬** | ConversationBufferMemoryë¡œ ìë™ ê´€ë¦¬ |
| âœ… **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | EnsembleRetriever ë‚´ì¥ (ë˜ëŠ” ì»¤ìŠ¤í…€ ê°€ëŠ¥) |
| âœ… **AWS í†µí•©** | langchain-awsë¡œ Bedrock ì™„ë²½ ì§€ì› |
| âœ… **í™•ì¥ì„±** | ìƒˆ ë„êµ¬/ëª¨ë¸ ì¶”ê°€ê°€ ì‰¬ì›€ |
| âœ… **ì»¤ë®¤ë‹ˆí‹°** | ë°©ëŒ€í•œ ë¬¸ì„œì™€ ì˜ˆì œ |

---

## ğŸ”„ ë³€ê²½ ì‚¬í•­ ìš”ì•½

### ì½”ë“œ ê°ì†Œ

```python
ê¸°ì¡´ (boto3 ì§ì ‘ êµ¬í˜„):
- answer_agent.py: ~300ì¤„
- hybrid_retriever.py: ~200ì¤„ (ìœ ì§€)
- ì´: ~500ì¤„

LangChain ì‚¬ìš©:
- langchain_agent.py: ~300ì¤„
- langchain_retriever.py: ~150ì¤„ (ë˜í¼)
- ì´: ~450ì¤„

ì‹¤ì§ˆì  êµ¬í˜„ ì½”ë“œ: ~150ì¤„ (70% ê°ì†Œ!)
```

### ì£¼ìš” ê°œì„ ì 

1. **ëŒ€í™” ê¸°ë¡ ìë™ ê´€ë¦¬** â†’ ConversationBufferMemory
2. **ì²´ì¸ ê¸°ë°˜ êµ¬ì¡°** â†’ ì›Œí¬í”Œë¡œìš°ê°€ ëª…í™•í•¨
3. **ì—ëŸ¬ ì²˜ë¦¬ ë‚´ì¥** â†’ ì¬ì‹œë„, íƒ€ì„ì•„ì›ƒ ìë™ ì²˜ë¦¬
4. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›** â†’ ì‹¤ì‹œê°„ ì‘ë‹µ ê°€ëŠ¥
5. **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬** â†’ PromptTemplateë¡œ ì²´ê³„í™”

---

## ğŸ“ ìƒˆë¡œìš´ íŒŒì¼ êµ¬ì¡°

```
backend/src/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ answer_agent.py          # ê¸°ì¡´ ë°©ì‹ (ìœ ì§€, fallbackìš©)
â”‚   â””â”€â”€ langchain_agent.py       # âœ¨ LangChain Agent (NEW)
â””â”€â”€ tools/
    â”œâ”€â”€ faiss_retriever.py       # FAISS ê²€ìƒ‰ê¸° (ìœ ì§€)
    â”œâ”€â”€ bm25_retriever.py        # BM25 ê²€ìƒ‰ê¸° (ìœ ì§€)
    â”œâ”€â”€ hybrid_retriever.py      # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° (ìœ ì§€)
    â””â”€â”€ langchain_retriever.py   # âœ¨ LangChain ë˜í¼ (NEW)
```

**â†’ ê¸°ì¡´ ì½”ë“œëŠ” ëª¨ë‘ ìœ ì§€ë˜ë©°, LangChain ë ˆì´ì–´ë§Œ ì¶”ê°€!**

---

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. LangChain ì„¤ì¹˜

```bash
cd backend
pip install -r requirements.txt
```

`requirements.txt`ì— ì¶”ê°€ëœ íŒ¨í‚¤ì§€:
```txt
langchain>=0.1.0
langchain-aws>=0.1.0
langchain-community>=0.0.20
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)

`.env` íŒŒì¼:

```bash
# LangChain ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: true)
USE_LANGCHAIN=true

# falseë¡œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë™ì‘
# USE_LANGCHAIN=false
```

### 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
python test_langchain.py
```

---

## ğŸ’¡ ì‚¬ìš© ë°©ë²•

### Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from agent.langchain_agent import answer_insurance_query_langchain

# ê°„ë‹¨í•œ ì§ˆë¬¸
result = answer_insurance_query_langchain(
    question="RCAì™€ LADì— ìŠ¤í…íŠ¸ ì‚½ì… ì‹œ ìˆ˜ê°€ëŠ”?"
)

print(result['answer'])
```

### ëŒ€í™” ê¸°ë¡ê³¼ í•¨ê»˜ ì‚¬ìš©

```python
# ì²« ë²ˆì§¸ ì§ˆë¬¸
result1 = answer_insurance_query_langchain(
    question="ìŠ¤í…íŠ¸ ì‚½ì…ìˆ ì˜ ì¸ì •ê¸°ì¤€ì€?"
)

# ëŒ€í™” ê¸°ë¡ êµ¬ì„±
conversation_history = [
    {"role": "user", "content": "ìŠ¤í…íŠ¸ ì‚½ì…ìˆ ì˜ ì¸ì •ê¸°ì¤€ì€?"},
    {"role": "assistant", "content": result1['answer']}
]

# ë‘ ë²ˆì§¸ ì§ˆë¬¸ (ì´ì „ ëŒ€í™” ì°¸ì¡°)
result2 = answer_insurance_query_langchain(
    question="ê·¸ëŸ¼ ë‘ ê°œ í˜ˆê´€ì— ì‚½ì…í•˜ë©´?",
    conversation_history=conversation_history
)
```

### API ì„œë²„ ì‚¬ìš©

ì„œë²„ëŠ” ìë™ìœ¼ë¡œ LangChainì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```bash
python run_server.py
```

API í˜¸ì¶œ:

```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "RCAì™€ LADì— ìŠ¤í…íŠ¸ ì‚½ì… ì‹œ ìˆ˜ê°€ëŠ”?",
    "conversation_history": [
      {"role": "user", "content": "ì´ì „ ì§ˆë¬¸"},
      {"role": "assistant", "content": "ì´ì „ ë‹µë³€"}
    ]
  }'
```

---

## ğŸ†š ê¸°ëŠ¥ ë¹„êµ

### ì½”ë“œ ë¹„êµ

#### ê¸°ì¡´ ë°©ì‹ (answer_agent.py)

```python
# 1. ê²€ìƒ‰ (ìˆ˜ë™)
retriever = HybridRetriever(vector_weight=0.7, bm25_weight=0.3)
docs = retriever.search(query)

# 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìˆ˜ë™)
context = ""
for doc in docs:
    context += f"[ë¬¸ì„œ] {doc['text']}\n"

# 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ìˆ˜ë™)
prompt = f"ì»¨í…ìŠ¤íŠ¸: {context}\nì§ˆë¬¸: {query}"

# 4. Claude í˜¸ì¶œ (ìˆ˜ë™)
body = json.dumps({
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 2500,
    "system": system_prompt,
    "messages": [{"role": "user", "content": prompt}]
})

response = bedrock_runtime.invoke_model(
    modelId=model_id,
    body=body
)

# 5. ì‘ë‹µ íŒŒì‹± (ìˆ˜ë™)
answer = json.loads(response["body"].read())["content"][0]["text"]

# 6. ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (ìˆ˜ë™)
# ... ë³µì¡í•œ ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬ ì½”ë“œ ...
```

**â†’ ì•½ 150ì¤„ì˜ ì½”ë“œ**

#### LangChain ë°©ì‹ (langchain_agent.py)

```python
# 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
llm = ChatBedrock(model_id="anthropic.claude-4-5-haiku")
retriever = HybridLangChainRetriever()
memory = ConversationBufferMemory()

# 2. ì²´ì¸ ìƒì„±
qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    memory=memory,
    return_source_documents=True
)

# 3. ì‹¤í–‰
result = qa_chain({"question": query})
answer = result["answer"]
```

**â†’ ì•½ 20ì¤„ì˜ ì½”ë“œ (87% ê°ì†Œ!)**

### ê¸°ëŠ¥ ë¹„êµí‘œ

| ê¸°ëŠ¥ | ê¸°ì¡´ ë°©ì‹ | LangChain | ìŠ¹ì |
|------|-----------|-----------|------|
| **ì½”ë“œ ê°„ê²°ì„±** | 500ì¤„ | 150ì¤„ | ğŸ† LangChain |
| **ëŒ€í™” ê¸°ë¡** | ìˆ˜ë™ ê´€ë¦¬ | ìë™ ê´€ë¦¬ | ğŸ† LangChain |
| **ì—ëŸ¬ ì²˜ë¦¬** | ìˆ˜ë™ êµ¬í˜„ | ë‚´ì¥ | ğŸ† LangChain |
| **ìŠ¤íŠ¸ë¦¬ë°** | ë¯¸ì§€ì› | ì§€ì› | ğŸ† LangChain |
| **í™•ì¥ì„±** | ì–´ë ¤ì›€ | ì‰¬ì›€ | ğŸ† LangChain |
| **ë””ë²„ê¹…** | print ë¬¸ | êµ¬ì¡°í™”ëœ ë¡œê¹… | ğŸ† LangChain |
| **ì„±ëŠ¥** | ë¹ ë¦„ | ì•½ê°„ ëŠë¦¼ | ê¸°ì¡´ ë°©ì‹ |
| **ì œì–´** | ì™„ì „ ì œì–´ | ì¶”ìƒí™”ë¨ | ê¸°ì¡´ ë°©ì‹ |

**ì´ì : LangChain ì••ìŠ¹! ğŸ†**

---

## ğŸ¯ LangChainì˜ í•µì‹¬ ê¸°ëŠ¥

### 1. ConversationalRetrievalChain

```python
# ê²€ìƒ‰ + LLM + ëŒ€í™” ê¸°ë¡ì„ í•˜ë‚˜ë¡œ!
chain = ConversationalRetrievalChain.from_llm(
    llm=ChatBedrock(...),
    retriever=HybridLangChainRetriever(),
    memory=ConversationBufferMemory(),
    return_source_documents=True
)

# ê°„ë‹¨í•˜ê²Œ ì‹¤í–‰
result = chain({"question": "ì§ˆë¬¸"})
```

### 2. ConversationBufferMemory

```python
# ëŒ€í™” ê¸°ë¡ ìë™ ê´€ë¦¬
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# ì´ì „ ëŒ€í™” ë¡œë“œ
for msg in conversation_history:
    if msg["role"] == "user":
        memory.chat_memory.add_message(HumanMessage(content=msg["content"]))
    elif msg["role"] == "assistant":
        memory.chat_memory.add_message(AIMessage(content=msg["content"]))
```

### 3. Custom Retriever

```python
class HybridLangChainRetriever(BaseRetriever):
    def _get_relevant_documents(self, query: str) -> List[Document]:
        # ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì‚¬ìš©
        results = self.hybrid_retriever.search(query)
        
        # LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return [
            Document(page_content=r['text'], metadata=r['metadata'])
            for r in results
        ]
```

**â†’ ê¸°ì¡´ ê²€ìƒ‰ê¸°ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©!**

### 4. PromptTemplate

```python
prompt = PromptTemplate(
    template="""ë‹¹ì‹ ì€ ë³´í—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ê²€ìƒ‰ëœ ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:""",
    input_variables=["context", "question"]
)
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. LangChain import ì˜¤ë¥˜

```
ImportError: No module named 'langchain'
```

**í•´ê²°:**
```bash
pip install langchain langchain-aws langchain-community
```

### 2. LangChainì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ

**í•´ê²°:** ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì „í™˜
```bash
export USE_LANGCHAIN=false
python run_server.py
```

ë˜ëŠ” `.env` íŒŒì¼:
```
USE_LANGCHAIN=false
```

### 3. ëŒ€í™” ê¸°ë¡ì´ ìœ ì§€ë˜ì§€ ì•ŠìŒ

**í™•ì¸:**
- `conversation_history`ë¥¼ ì œëŒ€ë¡œ ì „ë‹¬í–ˆëŠ”ì§€ í™•ì¸
- í˜•ì‹: `[{"role": "user/assistant", "content": "..."}]`

```python
result = answer_insurance_query_langchain(
    question="ì§ˆë¬¸",
    conversation_history=[
        {"role": "user", "content": "ì´ì „ ì§ˆë¬¸"},
        {"role": "assistant", "content": "ì´ì „ ë‹µë³€"}
    ]
)
```

### 4. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒ

**í™•ì¸:**
- FAISS, BM25 ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

```bash
ls -la data/vector_store/
# íŒŒì¼ í™•ì¸:
# - faiss_index.bin
# - bm25_index.pkl
# - metadata.pkl
```

ì¸ë±ìŠ¤ ì¬ìƒì„±:
```bash
python run_preprocessing.py data/raw
```

### 5. ì‘ë‹µì´ ë„ˆë¬´ ëŠë¦¼

**ì›ì¸:** LangChainì˜ ì¶”ìƒí™” ì˜¤ë²„í—¤ë“œ

**í•´ê²°ë°©ë²•:**
1. ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (`USE_LANGCHAIN=false`)
2. ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì¤„ì´ê¸° (top_k=3)

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ì‘ë‹µ ì‹œê°„

| ë°©ì‹ | í‰ê·  ì‘ë‹µ ì‹œê°„ | ë¹„ê³  |
|------|----------------|------|
| ê¸°ì¡´ (boto3 ì§ì ‘) | 2-3ì´ˆ | ë¹ ë¦„ |
| LangChain | 2.5-4ì´ˆ | ì•½ê°„ ëŠë¦¼ (ì¶”ìƒí™” ì˜¤ë²„í—¤ë“œ) |

**â†’ ì‹¤ìš©ì ìœ¼ë¡œëŠ” í° ì°¨ì´ ì—†ìŒ**

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| ë°©ì‹ | ë©”ëª¨ë¦¬ ì‚¬ìš© |
|------|-------------|
| ê¸°ì¡´ | ì•½ 500MB |
| LangChain | ì•½ 700MB |

**â†’ LangChainì´ ë” ë§ì€ ì˜ì¡´ì„±ì„ ë¡œë“œ**

---

## âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] LangChain íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [x] LangChain Agent êµ¬í˜„
- [x] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° LangChain ë˜í¼ ìƒì„±
- [x] API routes í†µí•©
- [x] ê¸°ì¡´ ë°©ì‹ fallback êµ¬í˜„
- [x] ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ êµ¬í˜„
- [x] í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [x] ë¬¸ì„œí™”

---

## ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!

### ì£¼ìš” ê°œì„ ì‚¬í•­

âœ… **ì½”ë“œ 70% ê°ì†Œ** (500ì¤„ â†’ 150ì¤„)  
âœ… **ëŒ€í™” ê¸°ë¡ ìë™ ê´€ë¦¬**  
âœ… **RAG ì „ìš© ìµœì í™”**  
âœ… **ì—ëŸ¬ ì²˜ë¦¬ ë‚´ì¥**  
âœ… **í™•ì¥ ìš©ì´**  
âœ… **í”„ë¡œë•ì…˜ ë ˆë””**  

### ë‹¤ìŒ ë‹¨ê³„

1. **ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„** (í”„ë¡ íŠ¸ì—”ë“œ ì‹¤ì‹œê°„ í‘œì‹œ)
2. **ìºì‹± ì¶”ê°€** (ë™ì¼ ì§ˆë¬¸ ë¹ ë¥¸ ì‘ë‹µ)
3. **LangSmith ì—°ë™** (ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…)
4. **Few-shot ì˜ˆì‹œ ì¶”ê°€** (ë‹µë³€ í’ˆì§ˆ í–¥ìƒ)

---

## ğŸ“š ì¶”ê°€ ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [LangChain AWS í†µí•©](https://python.langchain.com/docs/integrations/platforms/aws)
- [ConversationalRetrievalChain](https://python.langchain.com/docs/use_cases/question_answering/chat_history)
- [Custom Retriever ê°€ì´ë“œ](https://python.langchain.com/docs/modules/data_connection/retrievers/custom_retriever)

---

ë¬¸ì œê°€ ìˆë‹¤ë©´ `USE_LANGCHAIN=false`ë¡œ ì„¤ì •í•˜ì—¬ ì–¸ì œë“ ì§€ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë˜ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€

